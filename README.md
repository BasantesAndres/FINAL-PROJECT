# ğŸ¬ Movie Recommendation System: ALS vs SGD Matrix Factorization

[![C++](https://img.shields.io/badge/C%2B%2B-17-blue.svg)](https://en.cppreference.com/w/cpp/17)
[![Dataset](https://img.shields.io/badge/Dataset-MovieLens%20100K-orange.svg)](https://grouplens.org/datasets/movielens/100k/)

A comprehensive **C++ implementation** and **comparative study** of two matrix factorization algorithms for movie recommendation systems: **Alternating Least Squares (ALS)** and **Stochastic Gradient Descent (SGD)**. This project provides detailed performance analysis, evaluation metrics, architectural overview, and production-oriented insights.

---

## ğŸŒŸ Key Highlights

- **Superior ALS Performance**: 18.45% RMSE improvement over SGD
- **Production-Ready C++ Code**: Clean, optimized, modern C++
- **Detailed Evaluation**: Accuracy, convergence, and scalability comparisons
- **Research-Based**: Based on academic methodology and experimentation
- **Real Dataset**: Uses the MovieLens 100K benchmark dataset

---

## ğŸ“Š Performance Results

| Algorithm | Final RMSE | Final MAE | Improvement | Convergence |
|-----------|------------|-----------|-------------|-------------|
| **ALS**   | **0.6849** | **0.5263** | **18.45%**  | Fast (10 iterations) |
| **SGD**   | 0.8357     | 0.6667     | 12.72%      | Gradual (30+ iterations) |

### ğŸ” Convergence Patterns

- **ALS**: Rapid initial improvement; plateaus after ~10 iterations
- **SGD**: Consistent, gradual improvement throughout training

---

## ğŸ§  What is a Recommender System?

A **recommender system** is a machine learning model that predicts and suggests items (movies, music, products, etc.) a user might like, based on past interactions.

### ğŸ¯ Why Use Recommenders?

- **Personalization**: Tailor content to individual users
- **Discovery**: Help users explore new items
- **Engagement**: Increase time spent on platform
- **Conversion**: Boost sales or usage (Netflix, Amazon, Spotify)
- **User Experience**: Make platforms more intuitive and helpful

### ğŸ’¡ Real-World Examples

- **Netflix**: â€œRecommended for youâ€
- **Amazon**: â€œCustomers also boughtâ€¦â€
- **Spotify**: â€œDiscover Weeklyâ€
- **YouTube**: â€œSuggested Videosâ€

### âš ï¸ The Sparsity Problem

Users only interact with a tiny fraction of items:

- Netflix users rate <1% of all titles
- Amazon shoppers buy only a few of millions of products
- Results in >95% of the user-item matrix being empty

---

## ğŸ”¢ What is Matrix Factorization?

Matrix factorization is a mathematical technique that breaks a large, sparse matrix into two smaller, dense ones capturing **latent features** of users and items.

### ğŸ­ Conceptual Example

Imagine each movie and user described by hidden features:

**Movie latent vector**:
- Action: 0.8
- Romance: 0.2
- Comedy: 0.6

**User preference vector**:
- Likes action: 0.9
- Likes romance: 0.1
- Likes comedy: 0.7

**Predicted Rating** = dot(user, movie) = (0.9Ã—0.8) + (0.1Ã—0.2) + (0.7Ã—0.6) = 1.16

### ğŸ§® Mathematical Representation

Original Matrix (R) â‰ˆ User Matrix (U) Ã— Item Matrix (Váµ€)
[943 Ã— 1682] = [943 Ã— k] Ã— [k Ã— 1682]

yaml
Copiar
Editar

Where `k` is the number of latent dimensions.

---

## ğŸ§  Algorithms Implemented

### ğŸ”¸ Alternating Least Squares (ALS)

**How It Works**:

1. Initialize U and V randomly
2. Fix V and solve for U using least squares
3. Fix U and solve for V
4. Repeat until convergence


Offline batch processing

High-accuracy systems

Scenarios where parallel processing is possible


**âœ… Advantages:**
- **Fast Convergence**: Achieves optimal performance in fewer iterations
- **Parallelizable**: User/item updates can be computed independently
- **Stable**: Direct analytical optimization prevents gradient instability
- **Batch Processing**: Ideal for offline recommendation systems

**âŒ Disadvantages:**
- **Memory Intensive**: Requires matrix inversions and more storage
- **Computational Cost**: O(kÂ³ + nkÂ²) complexity per iteration
- **Batch Only**: Not suitable for real-time online learning



---

## ğŸ§  Algorithms Implemented

### ğŸ”¹ Stochastic Gradient Descent (SGD)
SGD updates factors incrementally using gradient-based optimization for each observed rating.


How It Works:

Initialize U and V with small values

For each known rating:

Compute error: e = rating - prediction

Update U and V using gradient descent

Repeat over many iterations

Best for:

Online/streaming systems

Low-memory environments

Simple implementations

**âœ… Advantages:**
- **Memory Efficient**: Low memory footprint with O(nk) complexity
- **Online Learning**: Supports real-time model updates
- **Simple Implementation**: Straightforward gradient-based approach
- **Scalable**: Works well with streaming data

**âŒ Disadvantages:**
- **Slower Convergence**: Requires more iterations for comparable accuracy
- **Parameter Sensitive**: Highly dependent on learning rate tuning
- **Sequential Processing**: Limited parallelization opportunities


---

## ğŸ—ï¸ Project Architecture

```
ğŸ“¦ movie-recommendation-cpp/
â”œâ”€â”€ ğŸ“ data/                 
â”‚   â””â”€â”€ ğŸ“„ ratings.csv            # Input dataset (movie ratings)
â”œâ”€â”€ ğŸ“ eigen/                    
â”‚   â””â”€â”€ ğŸ“„ [Eigen library]        # Eigen library used for algebraic operations
â”œâ”€â”€ ğŸ“„ als.cpp                      # ALS (Alternating Least Squares) implementation
â”œâ”€â”€ ğŸ“„ als.h                      # ALS (Alternating Least Squares) header
â”œâ”€â”€ ğŸ“„ als_metrics              # Evaluation metrics from ALS
â”œâ”€â”€ ğŸ“„ als_time                 # ALS training time
â”œâ”€â”€ ğŸ“„ extensions.cpp              # Additional extensions or configuration files
â”œâ”€â”€ ğŸ“„ extensions.h               # Additional header
â”œâ”€â”€ ğŸ“„ main.cpp                     # Main file that runs the program
â”œâ”€â”€ ğŸ“„ matrix_loader.cpp            # Loads matrix-format data
â”œâ”€â”€ ğŸ“„ matrix_loader.h            # Loads matrix-format data header
â”œâ”€â”€ ğŸ“„ metrics.cpp                  # Metric evaluation (e.g., RMSE, MAE)
â”œâ”€â”€ ğŸ“„ metrics.h                  # Metric evaluation (e.g., RMSE, MAE) header
â”œâ”€â”€ ğŸ“„ recommend                # Core logic of the recommendation system
â”œâ”€â”€ ğŸ“„ sgd,cpp                      # SGD (Stochastic Gradient Descent) implementation
â”œâ”€â”€ ğŸ“„ sgd.h                      # SGD (Stochastic Gradient Descent) header
â”œâ”€â”€ ğŸ“„ sgd_metrics              # Evaluation metrics from SGD
â”œâ”€â”€ ğŸ“„ sgd_time                 # SGD training time
â”œâ”€â”€ ğŸ“„ top5                    # Output with top 5 movie recommendations
â”œâ”€â”€ ğŸ“„ README                   # Project documentation

```

---

## âš™ï¸ Configuration & Hyperparameters

Customize the algorithms by modifying these parameters in `main.cpp`:

| Parameter | Description | Default | Range |
|-----------|-------------|---------|-------|
| `k` | Number of latent factors | 50 | 10-200 |
| `lambda` | Regularization parameter | 0.1 | 0.001-1.0 |
| `learning_rate` | SGD learning rate | 0.01 | 0.001-0.1 |
| `max_iterations` | Training iterations | 30 | 10-100 |
| `train_ratio` | Training/test split | 0.8 | 0.7-0.9 |


---

## ğŸ“ˆ Evaluation Metrics

### Root Mean Squared Error (RMSE)
Measures the square root of the average squared differences between predicted and actual ratings.

```cpp
RMSE = sqrt(Î£(predicted - actual)Â² / n)
```

### Mean Absolute Error (MAE)
Calculates the average absolute differences between predictions and ground truth.

```cpp
MAE = Î£|predicted - actual| / n
```

**Lower values indicate better performance for both metrics.**

---

## ğŸ”¬ Research Findings & Insights

### Algorithm Selection Guidelines

**Choose ALS when:**
- âœ… **Batch processing** is acceptable
- âœ… **High accuracy** is the primary requirement
- âœ… **Computational resources** are available
- âœ… **Parallel processing** can be leveraged
- âœ… **Offline recommendations** are sufficient

**Choose SGD when:**
- âœ… **Online learning** is required
- âœ… **Memory constraints** are significant  
- âœ… **Real-time updates** are necessary
- âœ… **Simple implementation** is preferred
- âœ… **Streaming data** scenarios

### Performance Analysis Summary

| Aspect | ALS | SGD |
|--------|-----|-----|
| **Accuracy** | Superior (18.45% better RMSE) | Good baseline performance |
| **Convergence** | Fast (10 iterations) | Gradual (30+ iterations) |
| **Memory Usage** | Higher | Lower |
| **Parallelization** | Excellent | Limited |
| **Implementation** | Complex (matrix ops) | Simple (gradient updates) |
| **Use Case** | Batch/offline systems | Online/streaming systems |

---

## ğŸ“š Dataset Information

This project uses the **MovieLens 100K** dataset:
- **100,000 ratings** from 943 users on 1,682 movies
- **Rating scale**: 1-5 stars
- **Sparsity**: ~95% (typical of real-world scenarios)
- **Format**: CSV with columns (user_id, item_id, rating)

The dataset simulates a real-world scenario similar to Netflix, where the vast majority of user-item pairs are unobserved, making accurate prediction challenging and practically relevant.

---

---

## ğŸ‘¨â€ğŸ’» Author

**Andres Alexander Basantes Balcazar**  
ğŸ“ School of Mathematical and Computational Sciences  
ğŸ« Universidad Yachay Tech, Ecuador  
ğŸ“§ [andres.basantes@yachaytech.edu.ec](mailto:andres.basantes@yachaytech.edu.ec)  

---
