# ğŸ¬ Movie Recommendation System: ALS vs SGD Matrix Factorization

[![C++](https://img.shields.io/badge/C%2B%2B-17-blue.svg)](https://en.cppreference.com/w/cpp/17)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)
[![Dataset](https://img.shields.io/badge/Dataset-MovieLens%20100K-orange.svg)](https://grouplens.org/datasets/movielens/100k/)

A comprehensive **C++ implementation** and **comparative study** of two popular matrix factorization algorithms for building movie recommendation systems. This project implements both **Alternating Least Squares (ALS)** and **Stochastic Gradient Descent (SGD)** algorithms from scratch, providing detailed performance analysis and practical insights for production systems.

## ğŸŒŸ Key Highlights

- **Superior ALS Performance**: 18.45% RMSE improvement over SGD
- **Production-Ready C++ Code**: Optimized implementations with modern C++ features
- **Comprehensive Analysis**: Detailed convergence patterns and computational trade-offs
- **Research-Backed**: Based on academic research with rigorous experimental methodology
- **Real-World Dataset**: Tested on MovieLens 100K with 100,000 ratings from 943 users

---

## ğŸ“Š Performance Results

Our experimental results demonstrate clear performance differences between the algorithms:

| Algorithm | Final RMSE | Final MAE | Improvement | Convergence Speed |
|-----------|------------|-----------|-------------|-------------------|
| **ALS**   | **0.6849** | **0.5263** | **18.45%** | Fast (10 iterations) |
| **SGD**   | 0.8357     | 0.6667     | 12.72%      | Gradual (30+ iterations) |

### ğŸ“ˆ Convergence Patterns
- **ALS**: Rapid initial improvement with stabilization after ~10 iterations
- **SGD**: Consistent gradual improvement throughout training process

---

## ğŸ§  Algorithm Deep Dive

### ğŸ”¸ Alternating Least Squares (ALS)
ALS alternates between fixing user factors and solving for item factors using closed-form least squares solutions.

```cpp
// Simplified ALS update formula
U_i = (V^T * V + Î»I)^(-1) * V^T * R_i
V_j = (U^T * U + Î»I)^(-1) * U^T * R_j
```

**âœ… Advantages:**
- **Fast Convergence**: Achieves optimal performance in fewer iterations
- **Parallelizable**: User/item updates can be computed independently
- **Stable**: Direct analytical optimization prevents gradient instability
- **Batch Processing**: Ideal for offline recommendation systems

**âŒ Disadvantages:**
- **Memory Intensive**: Requires matrix inversions and more storage
- **Computational Cost**: O(kÂ³ + nkÂ²) complexity per iteration
- **Batch Only**: Not suitable for real-time online learning

### ğŸ”¹ Stochastic Gradient Descent (SGD)
SGD updates factors incrementally using gradient-based optimization for each observed rating.

```cpp
// SGD update rules
error = R_ij - dot(U_i, V_j)
U_i += learning_rate * (error * V_j - lambda * U_i)
V_j += learning_rate * (error * U_i - lambda * V_j)
```

**âœ… Advantages:**
- **Memory Efficient**: Low memory footprint with O(nk) complexity
- **Online Learning**: Supports real-time model updates
- **Simple Implementation**: Straightforward gradient-based approach
- **Scalable**: Works well with streaming data

**âŒ Disadvantages:**
- **Slower Convergence**: Requires more iterations for comparable accuracy
- **Parameter Sensitive**: Highly dependent on learning rate tuning
- **Sequential Processing**: Limited parallelization opportunities

---

## ğŸ—ï¸ Project Architecture

```
ğŸ“¦ movie-recommendation-cpp/
â”œâ”€â”€ ğŸ“ data/
â”‚   â””â”€â”€ ğŸ“„ ratings.csv              # Preprocessed MovieLens 100K dataset
â”œâ”€â”€ ğŸ“ include/
â”‚   â”œâ”€â”€ ğŸ“„ ALS.hpp                  # ALS algorithm header
â”‚   â”œâ”€â”€ ğŸ“„ SGD.hpp                  # SGD algorithm header
â”‚   â”œâ”€â”€ ğŸ“„ MatrixFactorization.hpp  # Base class interface
â”‚   â””â”€â”€ ğŸ“„ utils.hpp                # Utility functions and metrics
â”œâ”€â”€ ğŸ“ src/
â”‚   â”œâ”€â”€ ğŸ“„ ALS.cpp                  # ALS implementation
â”‚   â”œâ”€â”€ ğŸ“„ SGD.cpp                  # SGD implementation
â”‚   â”œâ”€â”€ ğŸ“„ main.cpp                 # Main program and experiments
â”‚   â””â”€â”€ ğŸ“„ utils.cpp                # Helper functions
â”œâ”€â”€ ğŸ“ results/
â”‚   â”œâ”€â”€ ğŸ“„ performance_metrics.txt  # Final RMSE/MAE results
â”‚   â””â”€â”€ ğŸ“„ convergence_data.csv     # Iteration-by-iteration metrics
â”œâ”€â”€ ğŸ“ plots/
â”‚   â”œâ”€â”€ ğŸ“Š als_convergence.png      # ALS learning curves
â”‚   â””â”€â”€ ğŸ“Š sgd_convergence.png      # SGD learning curves
â”œâ”€â”€ ğŸ“„ Makefile                     # Build configuration
â”œâ”€â”€ ğŸ“„ requirements.txt             # Dataset requirements
â””â”€â”€ ğŸ“„ README.md                    # This file
```

---

## ğŸš€ Quick Start

### Prerequisites
- **C++17** compatible compiler (GCC 7+, Clang 5+, or MSVC 2017+)
- **Make** build system
- **Git** for cloning the repository

### Installation & Execution

1. **Clone the repository:**
   ```bash
   git clone https://github.com/yourusername/movie-recommendation-cpp.git
   cd movie-recommendation-cpp
   ```

2. **Download the dataset:**
   ```bash
   # The MovieLens 100K dataset will be automatically processed
   # Or manually download from: https://grouplens.org/datasets/movielens/100k/
   ```

3. **Build the project:**
   ```bash
   make clean && make
   ```

4. **Run the comparative analysis:**
   ```bash
   ./recommender
   ```

5. **View results:**
   ```bash
   # Performance metrics
   cat results/performance_metrics.txt
   
   # Convergence analysis
   cat results/convergence_data.csv
   ```

---

## âš™ï¸ Configuration & Hyperparameters

Customize the algorithms by modifying these parameters in `main.cpp`:

| Parameter | Description | Default | Range |
|-----------|-------------|---------|-------|
| `k` | Number of latent factors | 50 | 10-200 |
| `lambda` | Regularization parameter | 0.1 | 0.001-1.0 |
| `learning_rate` | SGD learning rate | 0.01 | 0.001-0.1 |
| `max_iterations` | Training iterations | 30 | 10-100 |
| `train_ratio` | Training/test split | 0.8 | 0.7-0.9 |

### Example Configuration:
```cpp
// Optimal parameters found through experimentation
const int k = 50;              // Latent factors
const double lambda = 0.1;     // Regularization
const double eta = 0.01;       // SGD learning rate
const int iterations = 30;     // Max iterations
```

---

## ğŸ“ˆ Evaluation Metrics

### Root Mean Squared Error (RMSE)
Measures the square root of the average squared differences between predicted and actual ratings.

```cpp
RMSE = sqrt(Î£(predicted - actual)Â² / n)
```

### Mean Absolute Error (MAE)
Calculates the average absolute differences between predictions and ground truth.

```cpp
MAE = Î£|predicted - actual| / n
```

**Lower values indicate better performance for both metrics.**

---

## ğŸ”¬ Research Findings & Insights

### Algorithm Selection Guidelines

**Choose ALS when:**
- âœ… **Batch processing** is acceptable
- âœ… **High accuracy** is the primary requirement
- âœ… **Computational resources** are available
- âœ… **Parallel processing** can be leveraged
- âœ… **Offline recommendations** are sufficient

**Choose SGD when:**
- âœ… **Online learning** is required
- âœ… **Memory constraints** are significant  
- âœ… **Real-time updates** are necessary
- âœ… **Simple implementation** is preferred
- âœ… **Streaming data** scenarios

### Performance Analysis Summary

| Aspect | ALS | SGD |
|--------|-----|-----|
| **Accuracy** | Superior (18.45% better RMSE) | Good baseline performance |
| **Convergence** | Fast (10 iterations) | Gradual (30+ iterations) |
| **Memory Usage** | Higher | Lower |
| **Parallelization** | Excellent | Limited |
| **Implementation** | Complex (matrix ops) | Simple (gradient updates) |
| **Use Case** | Batch/offline systems | Online/streaming systems |

---

## ğŸ› ï¸ Advanced Features & Optimization

### Code Optimizations Implemented:
- **Memory-efficient** sparse matrix representations
- **Vectorized operations** for improved performance
- **Cache-friendly** data access patterns
- **Early stopping** based on validation metrics
- **Regularization** to prevent overfitting

### Future Enhancements:
- [ ] **Parallel ALS** implementation using OpenMP
- [ ] **Mini-batch SGD** for improved stability
- [ ] **Adaptive learning rates** (Adam, RMSprop)
- [ ] **Implicit feedback** support
- [ ] **Deep learning hybrid** models
- [ ] **Distributed computing** with Apache Spark

---

## ğŸ“š Dataset Information

This project uses the **MovieLens 100K** dataset:
- **100,000 ratings** from 943 users on 1,682 movies
- **Rating scale**: 1-5 stars
- **Sparsity**: ~95% (typical of real-world scenarios)
- **Format**: CSV with columns (user_id, item_id, rating)

The dataset simulates a real-world scenario similar to Netflix, where the vast majority of user-item pairs are unobserved, making accurate prediction challenging and practically relevant.

---

## ğŸ¤ Contributing

We welcome contributions! Here's how you can help:

1. **Fork** the repository
2. **Create** a feature branch (`git checkout -b feature/amazing-feature`)
3. **Commit** your changes (`git commit -m 'Add amazing feature'`)
4. **Push** to the branch (`git push origin feature/amazing-feature`)
5. **Open** a Pull Request

### Areas for Contribution:
- Performance optimizations
- Additional algorithms (NMF, Deep Learning)
- Better visualization tools
- Code documentation improvements
- Bug fixes and testing

---

## ğŸ“ Citation

If you use this code in your research, please cite:

```bibtex
@misc{basantes2024movie,
  title={A C++ Implementation and Comparative Study of ALS and SGD for Movie Recommendation Using Matrix Factorization},
  author={Basantes Balcazar, Andres Alexander},
  year={2024},
  institution={Universidad Yachay Tech},
  url={https://github.com/yourusername/movie-recommendation-cpp}
}
```

---

## ğŸ‘¨â€ğŸ’» Author

**Andres Alexander Basantes Balcazar**  
ğŸ“ School of Mathematical and Computational Sciences  
ğŸ« Universidad Yachay Tech, Ecuador  
ğŸ“§ [andres.basantes@yachaytech.edu.ec](mailto:andres.basantes@yachaytech.edu.ec)  
ğŸ”— [LinkedIn](https://linkedin.com/in/yourusername) | [GitHub](https://github.com/yourusername)

---

## ğŸ“„ License

This project is licensed under the **MIT License** - see the [LICENSE](LICENSE) file for details.

---

## ğŸ™ Acknowledgments

- **GroupLens Research** for providing the MovieLens dataset
- **Universidad Yachay Tech** for academic support
- **Netflix Prize** competition for inspiring matrix factorization research
- **Open source community** for C++ libraries and tools

---

<div align="center">

**â­ Star this repository if you found it helpful! â­**

Made with â¤ï¸ for the recommender systems community

</div>
